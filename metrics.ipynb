{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "77296107-9248-407c-b2c5-c28bb92ed8a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Mapping, Sequence\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "\n",
    "K = 10\n",
    "ndcg_weights = 1.0 / np.log2(np.arange(0, K) + 2)\n",
    "ndcg_idcg = ndcg_weights.cumsum()\n",
    "\n",
    "\n",
    "def evaluate(ref_path, pred_path, train_path):\n",
    "\n",
    "    submission = pl.read_parquet(pred_path)\n",
    "    ref_df = pl.read_parquet(ref_path)\n",
    "    train = pl.read_parquet(train_path)\n",
    "\n",
    "    submission = (\n",
    "        submission\n",
    "        .select(\n",
    "            pl.col(\"user_id\").cast(pl.Int64),\n",
    "            pl.col(\"item_id\").cast(pl.List(pl.Int64)).alias(\"predicted\"),\n",
    "        )\n",
    "        .unique(subset=\"user_id\")\n",
    "        .with_columns(\n",
    "            pl.col(\"predicted\").list.unique(maintain_order=True)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ground_truth = ref_df.with_columns(pl.col(\"item_id\").alias(\"ground_truth\"))\n",
    "\n",
    "    submission_with_gt = ground_truth.join(submission, on=\"user_id\", how=\"left\")\n",
    "\n",
    "    metrics_per_user = submission_with_gt.select(\n",
    "        pl.col(\"user_id\"),\n",
    "        pl.struct(\"predicted\", \"ground_truth\").apply(ndcg_per_user).alias(\"ndcg\"),\n",
    "    )\n",
    "    mean_ndcg = metrics_per_user.select(pl.col(\"ndcg\").mean())[\"ndcg\"][0]\n",
    "    \n",
    "    metrics_per_user = submission_with_gt.select(\n",
    "        pl.col(\"user_id\"),\n",
    "        pl.struct(\"predicted\", \"ground_truth\").apply(hitrate_per_user).alias(\"hitrate\"),\n",
    "    )\n",
    "    mean_hitrate = metrics_per_user.select(pl.col(\"hitrate\").mean())[\"hitrate\"][0]\n",
    "    \n",
    "    coverage = compute_coverage(submission, train)\n",
    "    novelty = compute_novelty(submission, train)\n",
    "\n",
    "    return {'ndcg': mean_ndcg,\n",
    "            'hitrate': mean_hitrate,\n",
    "            'coverage': coverage,\n",
    "            'novelty': novelty}\n",
    "\n",
    "\n",
    "def ndcg_per_user(pl_struct: Mapping[str, Sequence[int]]) -> float:\n",
    "\n",
    "    predicted = pl_struct[\"predicted\"]\n",
    "    ground_truth = pl_struct[\"ground_truth\"]\n",
    "\n",
    "    if predicted is None:\n",
    "        return 0.0\n",
    "\n",
    "    assert ground_truth is not None\n",
    "    assert len(ground_truth) > 0\n",
    "\n",
    "    predicted_np = np.array(predicted[:K])\n",
    "    ground_truth_np = np.array(ground_truth)\n",
    "\n",
    "    predicted_count = min(len(predicted_np), K)\n",
    "    gt_count = min(len(ground_truth_np), K)\n",
    "\n",
    "    hits = (predicted_np.reshape(-1, 1) == ground_truth_np.reshape(1, -1)).sum(axis=1)\n",
    "    dcg = (hits * ndcg_weights[:predicted_count]).sum()\n",
    "    idcg = ndcg_idcg[gt_count - 1]\n",
    "    ndcg = dcg / idcg\n",
    "    return ndcg\n",
    "\n",
    "\n",
    "def hitrate_per_user(pl_struct: Mapping[str, Sequence[int]]) -> float:\n",
    "\n",
    "    predicted = pl_struct[\"predicted\"]\n",
    "    ground_truth = pl_struct[\"ground_truth\"]\n",
    "\n",
    "    if predicted is None:\n",
    "        return 0.0\n",
    "\n",
    "    assert ground_truth is not None\n",
    "    assert len(ground_truth) > 0\n",
    "\n",
    "    predicted_np = np.array(predicted[:K])\n",
    "    ground_truth_np = np.array(ground_truth)\n",
    "\n",
    "    hitrate = int(len(np.intersect1d(predicted_np, ground_truth_np)) > 0)\n",
    "\n",
    "    return hitrate\n",
    "\n",
    "\n",
    "def compute_coverage(submission, train):\n",
    "    \n",
    "    list_of_lists = submission.select('predicted').to_series().to_list()\n",
    "    all_pred_items = [x for xs in list_of_lists for x in xs]\n",
    "    all_pred_items = set(all_pred_items)\n",
    "    \n",
    "    all_train_items = train.select('item_id').unique().to_series().to_list()\n",
    "    \n",
    "    coverage = len(all_pred_items.intersection(all_train_items)) / len(all_train_items)\n",
    "    \n",
    "    return coverage\n",
    "\n",
    "\n",
    "def compute_novelty(submission, train):\n",
    "    \n",
    "    num_interactions = len(train)\n",
    "    item_stats = train.groupby('item_id').count()\n",
    "    item_stats = item_stats.with_columns(-np.log2(pl.col('count') / num_interactions).alias('item_novelty'))\n",
    "    item_stats = item_stats.with_columns((pl.col('item_novelty') / np.log2(num_interactions)))\n",
    "    item_stats = item_stats.select('item_id', 'item_novelty').to_pandas()\n",
    "    \n",
    "    list_of_lists = submission.select('predicted').to_series().to_list()\n",
    "    all_pred_items = [x for xs in list_of_lists for x in xs]\n",
    "    num_recommendations = len(all_pred_items)\n",
    "    \n",
    "    recs_items = pd.Series(all_pred_items).value_counts().reset_index()\n",
    "    recs_items.columns = ['item_id', 'item_count']\n",
    "    recs_items = pd.merge(recs_items, item_stats)\n",
    "    recs_items['product'] = recs_items['item_count'] * recs_items['item_novelty']\n",
    "\n",
    "    novelty = recs_items['product'].sum() / num_recommendations\n",
    "\n",
    "    return novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5f2ff120-19ce-4f1e-a062-24a2e67db8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prediction_path = \"predict.parquet\"\n",
    "ground_truth_path = \"test_gt.parquet\"\n",
    "train_path = \"train.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca176ab5-cade-424e-8128-136bbb03a5d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluate(ground_truth_path, prediction_path, train_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recsys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
